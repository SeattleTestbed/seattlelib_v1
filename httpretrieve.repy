"""
<Program Name>
  httpretrieve.repy

<Started>
  August 19, 2009

<Author>
  Yafete Yemuru

<Purpose>
  Provides a method for retrieving content from web servers using the HTTP
  protocol. The content can be accessed as a file like object, or saved to
  a file or returned as a string.
"""




include urlparse.repy
include sockettimeout.repy
include urllib.repy




class HttpConnectionError:
  """
  Error indicating that the web server has unexpectedly dropped the
  connection.
  """




class HttpBrokenServerError:
  """
  Error indicating that the web server has sent us complete garbage instead
  of something resembling HTTP.
  """




def httpretrieve_open(url, postdata=None, querydata=None, \
    httpheaders=None, timeout=None):
  """
  <Purpose>
     Returns a file-like object that can be used to read the content from
     an HTTP server. Follows 3xx redirects.

  <Arguments>
    url:
           The URL to perform a GET or POST request on.
    postdata (optional):
           A dictionary of form data or a string to POST to the server.
           Passing a non-None value results in a POST request being sent
           to the server.
    querydata (optional):
           A dictionary of form data or a string to send as the query
           string to the server.

           If postdata is omitted, the URL is retrieved with GET. If
           both postdata and querydata are omitted, there is no query
           string sent in the request.

           For both querydata and postdata, strings are sent *unmodified*.
           This means you probably should encode them first, with
           urllib_quote().
    httpheaders (optional):
           A dictionary of supplemental HTTP request headers to add to the
           request.
    timeout (optional):
           A timeout for establishing a connection to the web server,
           sending headers, and reading the response headers.

           If excluded or None, never times out.

  <Exceptions>
    ValueError if given an invalid URL, or malformed limit or timeout
      values. This is also raised if the user attempts to call a method
      on the file-like object after closing it.

    HttpConnectionError if opening the connection fails, or if the
      connection is closed by the server before we expect.

    SocketTimeoutError if the timeout is exceeded.

    HttpBrokenServerError if the response or the Location response header
      is malformed.

  <Side Effects>
    None

  <Returns>
    Returns a file-like object which can be used to read the body of
    the response from the web server. The protocol version spoken by the
    server, status code, and response headers are available as members of
    the object.
  """

  starttime = getruntime()

  # Check if the URL is valid and get host, path, port and query
  (host, port, path) = _httpretrieve_parse_given_url(url)

  # Open connection to the web server
  try:
    sock = timeout_openconn(host, port)

  except Exception, e:
    if repr(e).startswith("timeout("):
      raise HttpConnectionError("Socket timed out connecting to host/port.")
    raise

  # build an HTTP request using the given port, host, path and query
  httpheader = _httpretrieve_buildhttprequest(httpheaders, port, host, \
      path, querydata, postdata)

  # send HTTP request to the web server
  sock.send(httpheader)

  # receive the header lines from the web server
  httpheaderlines = _httpretrieve_receive_httpheader(sock, \
      timeout, getruntime() - starttime)

  # get the status code and status message from the HTTP response
  (http_status_number, http_status_msg) = \
      _httpretrieve_get_httpstatuscode(httpheaderlines)

  if http_status_number == '200':
    contentlength = _httpretrieve_get_contentlength(httpheaderlines)
    return _httpretrieve_filelikeobject(sock, contentlength)

  elif http_status_number == '301' or http_status_number == '302':
    # redirect to the new location via recursion
    sock.close()
    redirect_location = _httpretrieve_httpredirect(httpheaderlines)
    return httpretrieve_open(redirect_location)

  else:
    # Raise an exception detailing the status code and content of the
    # page to the user.
    contentlength = _httpretrieve_get_contentlength(httpheaderlines)
    http_errorcontent = \
        _httpretrieve_receive_httperror_content(sock)




def httpretrieve_save_file(url, filename, querydata=None, postdata=None, \
    httpheaders=None, timeout=None):
  """
  <Purpose>
    Perform an HTTP request, and save the content of the response to a
    file.

  <Arguments>
    filename:
           The file name to save the response to.
    Other arguments:
           See documentation for httpretrieve_open().

  <Exceptions>
    This function will raise any exception raised by Repy file objects
    in opening, writing to, and closing the file.

    This function will all also raise any exception raised by
    httpretrieve_open(), for the same reasons.

  <Side Effects>
    Writes the body of the response to 'filename'.

  <Returns>
    None
  """

  httpcontent = ''
  newfile = open(filename, 'w')

  http_obj = httpretrieve_open(url, querydata, postdata, httpheaders, \
      timeout)

  # Read from the file-like HTTP object into our file.
  while True:
    httpcontent = http_obj.read(1024)
    if httpcontent == '':
      # we're done reading
      newfile.close()
      http_obj.close()
      break
    newfile.write(httpcontent)




def httpretrieve_get_string(url, querydata=None, postdata=None, \
    httpheaders=None, timeout=30):
  """
  <Purpose>
    Performs an HTTP request on the given URL, using POST or GET,
    returning the content of the response as a string. Uses
    httpretrieve_open.

  <Arguments>
    See httpretrieve_open.

  <Exceptions>
    See httpretrieve_open.

  <Side Effects>
    None.

  <Returns>
    Returns the body of the HTTP response (no headers).
  """

  http_obj = httpretrieve_open(url, querydata, postdata, httpheaders, \
      timeout)
  httpcontent = http_obj.read()
  http_obj.close()
  return httpcontent




class _httpretrieve_filelikeobject:
  # This class implements a file-like object used for performing HTTP
  # requests and retrieving responses.

  def __init__(self, sock, contentlength):
    self.sock = sock
    if contentlength == None:
      self.contentlengthisknown = False
    else:
      self.contentlengthisknown = True
      self.contentlength = contentlength
    self.timeout = timeout
    self.fileobjclosed = False
    self.totalcontentisreceived = False
    self.totalread = 0



  def read(self, limit=None, timeout=None):
    """
    <Purpose>
      Behaves like Python's file.read(), with the potential to raise
      additional informative exceptions.

    <Arguments>
      limit (optional):
            The maximum amount of data to read. If omitted or None, this
            reads all available data.

    <Exceptions>
      See file.read()'s documentation, as well as that of
      httpretrieve_open().

    <Side Effects>
      None.

    <Returns>
      See file.read().
    """

    if self.fileobjclosed == True:
      raise ValueError("I/O operation on closed file")

    if self.totalcontentisreceived:
      return ''

    if limit == None:
      readhaslimit = False
      left_to_read = 1024
    else:
      # Sanity check type/value of limit
      if type(limit) is not int:
        raise TypeError("Expected an integer for limit")
      elif limit < 0:
        raise ValueError("Expected a non-negative integer for limit")

      readhaslimit = True
      left_to_read = limit

    if timeout is None:
      self.sock.settimeout(0)
    else:
      self.sock.settimeout(timeout)

    # Try to read up to limit, or until there is nothing left.
    httpcontent = ''
    while True:
      content = self.sock.recv(left_to_read)

      httpcontent += content
      if readhaslimit:
        self.totalread += len(content)
        if len(content) == left_to_read:
          break
        else:
          left_to_read -= len(content)

    return httpcontent



  def close(self):
    """
    <Purpose>
      Close the file-like object.

    <Arguments>
      None

    <Exceptions>
      None

    <Side Effects>
      Disconnects from the HTTP server.

    <Returns>
      Nothing
    """
    self.fileobjclosed = True
    self.sock.close()




def _httpretrieve_parse_given_url(url):
  # Checks that the URL is in the right format and returns a tuple of host,
  # port, path and query.
  urlparse = urlparse_urlsplit(url)
  if urlparse['scheme'] != 'http':
    raise ValueError("URL doesn't seem to be for the HTTP protocol.")
  if urlparse['hostname'] == None:
    raise ValueError("Missing hostname.")
  if urlparse['query'] is not None and urlparse['query'] != "":
    raise ValueError("URL cannot include a query string.")

  host = urlparse['hostname']
  path = urlparse['path']
  port = urlparse.get('port', 80)

  return (host, port, path)




def _httpretrieve_buildhttprequest(httpheaders, port, host, path, \
    querydata, postdata):
  # Builds the HTTP request.

  if postdata != None:
    # There is a posted data, use HTTP POST.

    if type(postdata) is dict:
      postdata = urllib_quote_parameters(postdata)

    if type(postdata) is not str:
      raise TypeError("postdata should be a dict of form data or string")

    # Build the minimal HTTP request header -- includes only the request
    # and the Host field.
    httpheader = _httpretrieve_httprequestmain_header('POST', querydata, \
        path, host, port)

    # Build the rest of the request.
    httpheader += _httpretrieve_parse_clienthttpheader(httpheaders)
    httpheader += 'Content-Length: ' + str(len(postdata)) + '\r\n'
    httpheader += '\r\n'
    httpheader += postdata

  else:
    # There is no posted data, use HTTP GET.
    httpheader = _httpretrieve_httprequestmain_header('GET', querydata, \
        path, host, port)
    httpheader += _httpretrieve_parse_clienthttpheader(httpheaders)
    httpheader += '\r\n'

  return httpheader




def _httpretrieve_httprequestmain_header(http_command, querydata, path, \
    host, port):
  # Builds a minimal HTTP request, returning it as a string.

  if type(querydata) is dict:
    querydata = urllib_quote_parameters(querydata)

  if type(querydata) is str and querydata != '':
    encoded_query = '?' + url_query
  else:
    encoded_query = ''

  # A non-empty path is a required part of an HTTP request.
  addpath = '/'
  if path != '':
    addpath = path

  main_httpheader = http_command + ' ' + addpath + encoded_query + \
      ' HTTP/1.0\r\n'

  # We don't need to include the port in the Host header if it is 80.
  addport = ''
  if port != 80:
    addport = ':' + str(port)

  main_httpheader += 'Host: ' + host + addport + '\r\n'
  return main_httpheader




def _httpretrieve_parse_clienthttpheader(httpheaders):
  # Converts a dictionary of HTTP request headers into a string.

  if httpheaders is None:
    return ''

  elif type(httpheaders) is not dict:
    raise TypeError("Expected HTTP headers as a dictionary.")

  else:
    clienthttpheader = ''
    for key, val in httpheaders.items():
      clienthttpheader += key + ': ' + val + '\r\n'
    return clienthttpheader




def _httpretrieve_receive_httpheader(sock, timeout, currentruntime):
  # Receives the HTTP headers only. Returns them as a list of strings.

  if timeout is None:
    sock.settimeout(0)
  elif timeout - currentruntime <= 0:
    raise SocketTimeoutError("Timed out")
  else:
    sock.settimeout(timeout - currentruntime)

  httpheader_received = 0
  httpheader = ''
  while True:
    # CRLFCRLF separates the HTTP headers from the body of the response.
    if httpheader.endswith('\r\n\r\n'):
      return httpheader.split('\r\n')

    content = sock.recv(1)
    httpheader_received += 1
    httpheader += content




def _httpretrieve_get_httpstatuscode(httpHeaderLines):
  # Checks if the status code does not indicate an error.

  # The first line of an HTTP response is composed of:
  # HTTP<version> http_status_number http_status_msg
  httpstatusheader = httpHeaderLines[0]
  headersplit = httpstatusheader.split(' ', 2)

  if len(headersplit) != 3:
    raise HttpBrokenServerError("Server returned garbage for HTTP response.")
  if not httpstatusheader.startswith('HTTP'):
    raise HttpBrokenServerError("Server returned garbage for HTTP response.")

  http_status_msg = headersplit[2]

  try:
    return (int(headersplit[1]), http_status_msg)
  except ValueError, e:
    raise HttpBrokenServerError("Server returned garbage for HTTP response.")




def _httpretrieve_receive_httperror_content(sock):
  # Receive the error message (this is called when the server returns an
  # 'error' response).

  httperror_content = ''
  while True:
    content = sock.recv(1024)
    httperror_content += content

  return httperror_content




def _httpretrieve_httpredirect(httpheaderlines):
  # Determine redirect location from response headers.

  for headerline in httpheaderlines:
    if headerline.startswith('Location: '):
      return headerline[len('Location: '):]

  raise HttpBrokenServerError("HTTP server indicated a redirect and did " + \
      "not send a Location header.")




def _httpretrieve_get_contentlength(httpheaderlines):
  # Determines the value of the Content-Length header.

  for headerline in httpheaderlines:
    if headerline.startswith('Content-Length: '):
      return int(headerline[len('Content-Length: '):])

  return None
