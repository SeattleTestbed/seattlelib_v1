"""
<Program Name>
  httpretrieve.repy

<Started>
  August 19, 2009

<Author>
  Yafete Yemuru

<Purpose>
  Provides a method for retrieving content from web servers using the HTTP
  protocol. The content can be accessed as a file like object, or saved to
  a file or returned as a string.
"""



include urlparse.repy
include sockettimeout.repy
include urllib.repy



class HttpConnectionError(Exception):
  """
  Error indicating that the web server has unexpectedly dropped the
  connection.
  """




class HttpBrokenServerError(Exception):
  """
  Error indicating that the web server has sent us complete garbage instead
  of something resembling HTTP.
  """




def httpretrieve_open(url, postdata=None, querydata=None, \
    httpheaders=None, timeout=None):
  """
  <Purpose>
     Returns a file-like object that can be used to read the content from
     an HTTP server. Follows 3xx redirects.

  <Arguments>
    url:
           The URL to perform a GET or POST request on.
    postdata (optional):
           A dictionary of form data or a string to POST to the server.
           Passing a non-None value results in a POST request being sent
           to the server.
    querydata (optional):
           A dictionary of form data or a string to send as the query
           string to the server.

           If postdata is omitted, the URL is retrieved with GET. If
           both postdata and querydata are omitted, there is no query
           string sent in the request.

           For both querydata and postdata, strings are sent *unmodified*.
           This means you probably should encode them first, with
           urllib_quote().
    httpheaders (optional):
           A dictionary of supplemental HTTP request headers to add to the
           request.
    timeout (optional):
           A timeout for establishing a connection to the web server,
           sending headers, and reading the response headers.

           If excluded or None, never times out.

  <Exceptions>
    ValueError if given an invalid URL, or malformed limit or timeout
      values. This is also raised if the user attempts to call a method
      on the file-like object after closing it.

    HttpConnectionError if opening the connection fails, or if the
      connection is closed by the server before we expect.

    SocketTimeoutError if the timeout is exceeded.

    HttpBrokenServerError if the response or the Location response header
      is malformed.

  <Side Effects>
    None

  <Returns>
    Returns a file-like object which can be used to read the body of
    the response from the web server. The protocol version spoken by the
    server, status code, and response headers are available as members of
    the object.
  """

  # TODO: Make sure the timeout actually works correctly everywhere it
  # should. I'm 99% sure it's broken somewhere.

  starttimefloat = getruntime()

  # Check if the URL is valid and get host, path, port and query
  parsedurldict = urlparse_urlsplit(url)
  hoststr = parsedurldict['hostname']
  pathstr = parsedurldict['path']
  portint = parsedurldict.get('port')
  portint = portint or 80

  if parsedurldict['scheme'] != 'http':
    raise ValueError("URL doesn't seem to be for the HTTP protocol.")
  if hoststr is None:
    raise ValueError("Missing hostname.")
  if parsedurldict['query'] is not None and parsedurldict['query'] != "":
    raise ValueError("URL cannot include a query string.")

  # Typical HTTP sessions consist of (optionally, a series of pairs of) HTTP
  # requests followed by HTTP responses. These happen serially.

  # Open connection to the web server
  try:
    sockobj = timeout_openconn(hoststr, portint)

  except Exception, e:
    if repr(e).startswith("timeout("):
      raise HttpConnectionError("Socket timed out connecting to host/port.")
    raise

  # Builds the HTTP request:
  httprequeststr = _httpretrieve_build_request(hoststr, portint, pathstr, \
      querydata, postdata, httpheaders)

  # Send the full HTTP request to the web server.
  _httpretrieve_sendall(sockobj, httprequeststr)

  # Now, we're done with the HTTP request part of the session, and we need
  # to get the HTTP response.

  # Check if we've timed out (if the user requested a timeout); update the
  # socket timeout to reflect the time taken sending the request.
  if timeout is None:
    sockobj.settimeout(0)
  elif getruntime() - starttimefloat >= timeout:
    raise SocketTimeoutError("Timed out")
  else:
    sockobj.settimeout(timeout - (getruntime() - starttimefloat))

  # Receive the header lines from the web server (a series of CRLF-terminated
  # lines, terminated by an empty line, or by the server closing the
  # connection.
  headersstr = ""
  while not headersstr.endswith("\r\n\r\n"):
    try:
      headersstr += sockobj.recv(1)
    except Exception, e:
      if str(e) == "Socket closed":
        break
      else:
        raise

  httpheaderlist = headersstr.split("\r\n")
  # Ignore (a) trailing blank line(s) (for example, the response header-
  # terminating blank line).
  while len(httpheaderlist) > 0 and httpheaderlist[-1] == "":
    httpheaderlist = httpheaderlist[:-1]

  # Get the status code and status message from the HTTP response.
  statuslinestr, httpheaderlines = httpheaderlines[0], httpheaderlines[1:]

  # The status line should be in the form: "HTTP/1.X NNN SSSSS", where
  # X is 0 or 1, NNN is a 3-digit status code, and SSSSS is a 'user-friendly'
  # string representation of the status code (may contain spaces).
  statuslinelist = statuslinestr.split(' ', 2)

  if len(statuslinelist) < 3:
    raise HttpBrokenServerError("Server returned garbage for HTTP " + \
        "response (status line missing one or more fields).")
  if not statuslinelist[0].startswith('HTTP'):
    raise HttpBrokenServerError("Server returned garbage for HTTP " + \
        "response (invalid response protocol in status line).")

  friendlystatusstr = statuslinelist[2]
  try:
    statusint = int(statuslinelist[1])
  except ValueError, e:
    raise HttpBrokenServerError("Server returned garbage for HTTP " + \
        "response (status code isn't integer).")

  httpheaderdict = _httpretrieve_parse_responseheaders(httpheaderlines)

  # If we got any sort of redirect response, follow the redirect. Note: we
  # do *not* handle the 305 status code (use the proxy as specified in the
  # Location header) at all; I think this is best handled at a higher layer
  # anyway.
  if statusint in (301, 302, 303, 307):
    sockobj.close()
    try:
      redirecturlstr = httpheaderdict["Location"][0]
    except (KeyError, IndexError), ke:
      # When a server returns a redirect status code (3xx) but no Location
      # header, some clients, e.g. Firefox, just show the response body
      # as they would normally for a 2xx or 4xx response. So, I think we
      # should ignore a missing Location header and just return the page
      # to the caller.
      pass
    else:
      # If the server did send a redirect location, let's go there.
      return httpretrieve_open(redirecturlstr)

  # If we weren't requested to redirect, and we didn't, return a read-only
  # file-like object (representing the response body) to the caller.
  return _httpretrieve_filelikeobject(sockobj, httpheaderdict, \
      (statuslinelist[0], statusint, friendlystatusstr))




def httpretrieve_save_file(url, filename, querydata=None, postdata=None, \
    httpheaders=None, timeout=None):
  """
  <Purpose>
    Perform an HTTP request, and save the content of the response to a
    file.

  <Arguments>
    filename:
           The file name to save the response to.
    Other arguments:
           See documentation for httpretrieve_open().

  <Exceptions>
    This function will raise any exception raised by Repy file objects
    in opening, writing to, and closing the file.

    This function will all also raise any exception raised by
    httpretrieve_open(), for the same reasons.

  <Side Effects>
    Writes the body of the response to 'filename'.

  <Returns>
    None
  """

  httpcontent = ''
  newfile = open(filename, 'w')

  http_obj = httpretrieve_open(url, querydata=querydata, postdata=postdata, \
      httpheaders=httpheaders, timeout=timeout)

  # Read from the file-like HTTP object into our file.
  while True:
    httpcontent = http_obj.read(4096)
    if httpcontent == '':
      # we're done reading
      newfile.close()
      http_obj.close()
      break
    newfile.write(httpcontent)




def httpretrieve_get_string(url, querydata=None, postdata=None, \
    httpheaders=None, timeout=30):
  """
  <Purpose>
    Performs an HTTP request on the given URL, using POST or GET,
    returning the content of the response as a string. Uses
    httpretrieve_open.

  <Arguments>
    See httpretrieve_open.

  <Exceptions>
    See httpretrieve_open.

  <Side Effects>
    None.

  <Returns>
    Returns the body of the HTTP response (no headers).
  """

  http_obj = httpretrieve_open(url, querydata=querydata, postdata=postdata, \
      httpheaders=httpheaders, timeout=timeout)
  httpcontent = http_obj.read()
  http_obj.close()
  return httpcontent




class _httpretrieve_filelikeobject:
  # This class implements a file-like object used for performing HTTP
  # requests and retrieving responses.

  def __init__(self, sock, headers, httpstatus):
    self._sock = sock
    self._fileobjclosed = False
    self._totalcontentisreceived = False
    self._totalread = 0
    self.headers = headers
    self.httpstatus = httpstatus



  def read(self, limit=None, timeout=None):
    """
    <Purpose>
      Behaves like Python's file.read(), with the potential to raise
      additional informative exceptions.

    <Arguments>
      limit (optional):
            The maximum amount of data to read. If omitted or None, this
            reads all available data.

    <Exceptions>
      See file.read()'s documentation, as well as that of
      httpretrieve_open().

    <Side Effects>
      None.

    <Returns>
      See file.read().
    """

    if self._fileobjclosed == True:
      raise ValueError("I/O operation on closed file")

    if self._totalcontentisreceived:
      return ''

    if limit is not None:
      # Sanity check type/value of limit
      if type(limit) is not int:
        raise TypeError("Expected an integer or None for limit")
      elif limit < 0:
        raise ValueError("Expected a non-negative integer for limit")

      lefttoread = limit
    else:
      lefttoread = None

    if timeout is None:
      self._sock.settimeout(0)
    else:
      self._sock.settimeout(timeout)

    # Try to read up to limit, or until there is nothing left.
    httpcontent = ''
    while True:
      try:
        content = self._sock.recv(lefttoread or 4096)
      except Exception, e:
        if str(e) == "Socket closed":
          self._totalcontentisreceived = True
          break
        else:
          raise
      
      httpcontent += content
      self._totalread += len(content)
      if limit is not None:
        if len(content) == lefttoread:
          break
        else:
          lefttoread -= len(content)
      if content == "":
        self._totalcontentisreceived = True
        break

    return httpcontent



  def close(self):
    """
    <Purpose>
      Close the file-like object.

    <Arguments>
      None

    <Exceptions>
      None

    <Side Effects>
      Disconnects from the HTTP server.

    <Returns>
      Nothing
    """
    self._fileobjclosed = True
    try:
      self._sock.close()
    except Exception, e:
      pass # don't care




def _httpserver_put_in_headerdict(res, lastheader, lastheader_str):
  # Tries to put the header into dictionary of lists, 'res'.
  if lastheader is not None:
    if lastheader not in res:
      res[lastheader] = []
    res[lastheader].append(lastheader_str.strip())




def _httpretrieve_parse_responseheaders(headerlines):
  # Parse rfc822-style headers (this could be abstracted out to an rfc822
  # library that would be quite useful for internet protocols). Returns
  # a dictionary mapping headers to arrays of values. E.g.:
  #
  # Foo: a
  # Bar:
  #   b
  # Bar: c
  #
  # Becomes: {"Foo": ["a"], "Bar": ["b", "c"]}

  lastheader = None
  lastheader_str = ""
  res = {}
  
  if len(headerlines) == 0:
    return {}

  try:
    # Iterate over the request header lines:
    for i in range(len(headerlines)):
      # Lines with leading non-CRLF whitespace characters are part of the
      # previous line.
      if headerlines[i][0] in (" ", "\t") and lastheader is not None:
        lastheader_str += headerlines[i]
      else:
        _httpserver_put_in_headerdict(res, lastheader, lastheader_str)
        lastheader, lastheader_str = headerlines[i].split(":", 1)

    # Add the last line to the dictionary.
    _httpserver_put_in_headerdict(res, lastheader, lastheader_str)

    return res
  except IndexError, idx:
    raise HttpBrokenServerError("Server returned garbage for HTTP" + \
        " response. Bad header.")




def _httpretrieve_build_request(host, port, path, querydata, postdata, \
    httpheaders):
  # Builds an HTTP request from these parameters, returning it as
  # a string.

  method = "GET"
  if postdata is not None:
    method = "POST"
    if type(postdata) is dict:
      postdata = urllib_quote_parameters(postdata)
    if type(postdata) is not str:
      raise TypeError("postdata should be a dict of form data or string")

  # Encode path / querystring part.
  if path == "":
    raise ValueError("Invalid path -- empty string.")
  if type(querydata) is dict:
    querydata = urllib_quote_parameters(querydata)
  if type(querydata) is str and querydata != "":
    encquerydata = "?" + querydata
  else:
    encquerydata = ""

  # Encode the request line and headers:
  httpheader = method + ' ' + path + encquerydata + ' HTTP/1.0\r\n'
  if httpheaders is not None:
    if type(httpheaders) is not dict:
      raise TypeError("Expected HTTP headers as a dictionary.")
    else:
      if "Host" not in httpheaders:
        httpheader += "Host: " + host + ':' + str(port) + "\r\n"
      for key, val in httpheaders.items():
        httpheader += key + ": " + val + '\r\n'

  # Affix post-data related headers and content:
  if method == "POST":
    httpheader += 'Content-Length: ' + str(len(postdata)) + '\r\n'
  httpheader += '\r\n'
  if method == "POST":
    httpheader += postdata

  return httpheader




def _httpretrieve_sendall(sock, data):
  # Attempts to send all of data to sock.
  while len(data) > 0:
    data = data[sock.send(data):]
